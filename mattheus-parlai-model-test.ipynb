{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:42:05 | \u001b[33mOverriding opt[\"model_file\"] to C:\\Users\\Mattheus\\anaconda3\\envs\\arp\\Lib\\site-packages\\data\\models\\pretrained_transformers/poly_model_huge_reddit/model (previously: /private/home/edinan/ParlAI/data/models/pretrained_transformers/poly_model_huge_reddit.mdl)\u001b[0m\n",
      "17:42:05 | loading dictionary from C:\\Users\\Mattheus\\anaconda3\\envs\\arp\\Lib\\site-packages\\data\\models\\pretrained_transformers/poly_model_huge_reddit/model.dict\n",
      "17:42:05 | num words = 54944\n",
      "17:42:05 | Polyencoder: full interactive mode on.\n",
      "17:42:05 | Setting fixed_candidates path to: C:\\Users\\Mattheus\\anaconda3\\envs\\arp\\Lib\\site-packages\\data\\models\\pretrained_transformers/poly_model_huge_reddit/model.cands-convai2.cands\n",
      "17:42:07 | Total parameters: 256,081,920 (256,081,920 trainable)\n",
      "17:42:07 | Loading existing model parameters from C:\\Users\\Mattheus\\anaconda3\\envs\\arp\\Lib\\site-packages\\data\\models\\pretrained_transformers/poly_model_huge_reddit/model\n",
      "17:42:08 | Loading fixed candidate set from C:\\Users\\Mattheus\\anaconda3\\envs\\arp\\Lib\\site-packages\\data\\models\\pretrained_transformers/poly_model_huge_reddit/model.cands-convai2.cands\n",
      "17:42:08 | Vectorizing fixed candidate set (257 batch(es) of up to 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257/257 [00:05<00:00, 50.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:42:14 | Saving fixed candidate set vectors to C:\\Users\\Mattheus\\anaconda3\\envs\\arp\\Lib\\site-packages\\data\\models\\pretrained_transformers/poly_model_huge_reddit\\model.convai_trainset_cands.vecs\n",
      "17:42:14 | Opt:\n",
      "17:42:14 |     activation: gelu\n",
      "17:42:14 |     adafactor_eps: '(1e-30, 0.001)'\n",
      "17:42:14 |     adam_eps: 1e-08\n",
      "17:42:14 |     add_p1_after_newln: False\n",
      "17:42:14 |     allow_missing_init_opts: False\n",
      "17:42:14 |     attention_dropout: 0.1\n",
      "17:42:14 |     batchsize: 2\n",
      "17:42:14 |     betas: '[0.9, 0.999]'\n",
      "17:42:14 |     bpe_add_prefix_space: None\n",
      "17:42:14 |     bpe_debug: False\n",
      "17:42:14 |     bpe_dropout: None\n",
      "17:42:14 |     bpe_merge: None\n",
      "17:42:14 |     bpe_vocab: None\n",
      "17:42:14 |     candidates: batch\n",
      "17:42:14 |     cap_num_predictions: 100\n",
      "17:42:14 |     checkpoint_activations: False\n",
      "17:42:14 |     codes_attention_num_heads: 4\n",
      "17:42:14 |     codes_attention_type: basic\n",
      "17:42:14 |     data_parallel: True\n",
      "17:42:14 |     datapath: C:\\Users\\Mattheus\\anaconda3\\envs\\arp\\Lib\\site-packages\\data\n",
      "17:42:14 |     datatype: train\n",
      "17:42:14 |     delimiter: '\\n'\n",
      "17:42:14 |     dict_class: parlai.core.dict:DictionaryAgent\n",
      "17:42:14 |     dict_endtoken: __start__\n",
      "17:42:14 |     dict_file: C:\\Users\\Mattheus\\anaconda3\\envs\\arp\\Lib\\site-packages\\data\\models\\pretrained_transformers/poly_model_huge_reddit/model.dict\n",
      "17:42:14 |     dict_initpath: None\n",
      "17:42:14 |     dict_language: english\n",
      "17:42:14 |     dict_loaded: True\n",
      "17:42:14 |     dict_lower: True\n",
      "17:42:14 |     dict_max_ngram_size: -1\n",
      "17:42:14 |     dict_maxtokens: -1\n",
      "17:42:14 |     dict_minfreq: 0\n",
      "17:42:14 |     dict_nulltoken: __null__\n",
      "17:42:14 |     dict_starttoken: __start__\n",
      "17:42:14 |     dict_textfields: text,labels\n",
      "17:42:15 |     dict_tokenizer: bpe\n",
      "17:42:15 |     dict_unktoken: __unk__\n",
      "17:42:15 |     display_add_fields: \n",
      "17:42:15 |     display_examples: False\n",
      "17:42:15 |     display_prettify: False\n",
      "17:42:15 |     download_path: None\n",
      "17:42:15 |     dropout: 0.1\n",
      "17:42:15 |     dynamic_batching: None\n",
      "17:42:15 |     embedding_projection: random\n",
      "17:42:15 |     embedding_size: 768\n",
      "17:42:15 |     embedding_type: random\n",
      "17:42:15 |     embeddings_scale: False\n",
      "17:42:15 |     encode_candidate_vecs: False\n",
      "17:42:15 |     encode_candidate_vecs_batchsize: 256\n",
      "17:42:15 |     eval_candidates: inline\n",
      "17:42:15 |     ffn_size: 3072\n",
      "17:42:15 |     fixed_candidate_vecs: reuse\n",
      "17:42:15 |     fixed_candidates_path: None\n",
      "17:42:15 |     force_fp16_tokens: True\n",
      "17:42:15 |     fp16: True\n",
      "17:42:15 |     fp16_impl: safe\n",
      "17:42:15 |     gpu: -1\n",
      "17:42:15 |     gradient_clip: 0.1\n",
      "17:42:15 |     hide_labels: False\n",
      "17:42:15 |     history_add_global_end_token: None\n",
      "17:42:15 |     history_reversed: False\n",
      "17:42:15 |     history_size: 20\n",
      "17:42:15 |     ignore_bad_candidates: False\n",
      "17:42:15 |     image_cropsize: 224\n",
      "17:42:15 |     image_mode: raw\n",
      "17:42:15 |     image_size: 256\n",
      "17:42:15 |     inference: max\n",
      "17:42:15 |     init_model: None\n",
      "17:42:15 |     init_opt: None\n",
      "17:42:15 |     interactive_candidates: fixed\n",
      "17:42:15 |     interactive_mode: True\n",
      "17:42:15 |     interactive_task: True\n",
      "17:42:15 |     invsqrt_lr_decay_gamma: -1\n",
      "17:42:15 |     is_debug: False\n",
      "17:42:15 |     label_truncate: 72\n",
      "17:42:15 |     learn_embeddings: True\n",
      "17:42:15 |     learn_positional_embeddings: True\n",
      "17:42:15 |     learningrate: 5e-05\n",
      "17:42:15 |     local_human_candidates_file: None\n",
      "17:42:15 |     log_keep_fields: all\n",
      "17:42:15 |     loglevel: info\n",
      "17:42:15 |     lr_scheduler: reduceonplateau\n",
      "17:42:15 |     lr_scheduler_decay: 0.4\n",
      "17:42:15 |     lr_scheduler_patience: 0\n",
      "17:42:15 |     memory_attention: sqrt\n",
      "17:42:15 |     model: transformer/polyencoder\n",
      "17:42:15 |     model_file: C:\\Users\\Mattheus\\anaconda3\\envs\\arp\\Lib\\site-packages\\data\\models\\pretrained_transformers/poly_model_huge_reddit/model\n",
      "17:42:15 |     model_parallel: False\n",
      "17:42:15 |     momentum: 0\n",
      "17:42:15 |     multitask_weights: [1]\n",
      "17:42:15 |     n_decoder_layers: -1\n",
      "17:42:15 |     n_encoder_layers: -1\n",
      "17:42:15 |     n_heads: 12\n",
      "17:42:15 |     n_layers: 12\n",
      "17:42:15 |     n_positions: 1024\n",
      "17:42:15 |     n_segments: 2\n",
      "17:42:15 |     nesterov: True\n",
      "17:42:15 |     no_cuda: False\n",
      "17:42:15 |     normalize_sent_emb: False\n",
      "17:42:15 |     numthreads: 1\n",
      "17:42:15 |     nus: [0.7]\n",
      "17:42:15 |     optimizer: adamax\n",
      "17:42:15 |     outfile: \n",
      "17:42:15 |     output_scaling: 0.06\n",
      "17:42:15 |     override: \"{'model_file': 'C:\\\\\\\\Users\\\\\\\\Mattheus\\\\\\\\anaconda3\\\\\\\\envs\\\\\\\\arp\\\\\\\\Lib\\\\\\\\site-packages\\\\\\\\data\\\\\\\\models\\\\\\\\pretrained_transformers/poly_model_huge_reddit/model'}\"\n",
      "17:42:15 |     parlai_home: /private/home/edinan/ParlAI\n",
      "17:42:15 |     person_tokens: False\n",
      "17:42:15 |     poly_attention_num_heads: 4\n",
      "17:42:15 |     poly_attention_type: basic\n",
      "17:42:15 |     poly_n_codes: 64\n",
      "17:42:15 |     polyencoder_type: n_first\n",
      "17:42:15 |     rank_candidates: True\n",
      "17:42:15 |     rank_top_k: -1\n",
      "17:42:15 |     reduction_type: mean\n",
      "17:42:15 |     relu_dropout: 0.0\n",
      "17:42:15 |     repeat_blocking_heuristic: True\n",
      "17:42:15 |     return_cand_scores: False\n",
      "17:42:15 |     save_format: conversations\n",
      "17:42:15 |     share_encoders: False\n",
      "17:42:15 |     share_word_embeddings: True\n",
      "17:42:15 |     show_advanced_args: False\n",
      "17:42:15 |     single_turn: False\n",
      "17:42:15 |     special_tok_lst: None\n",
      "17:42:15 |     split_lines: False\n",
      "17:42:15 |     starttime: Jul12_08-39\n",
      "17:42:15 |     task: convai2\n",
      "17:42:15 |     text_truncate: 360\n",
      "17:42:15 |     topk: 5\n",
      "17:42:15 |     train_predict: False\n",
      "17:42:15 |     truncate: 1024\n",
      "17:42:15 |     update_freq: 1\n",
      "17:42:15 |     use_memories: False\n",
      "17:42:15 |     use_reply: label\n",
      "17:42:15 |     variant: xlm\n",
      "17:42:15 |     verbose: False\n",
      "17:42:15 |     warmup_rate: 0.0001\n",
      "17:42:15 |     warmup_updates: 100\n",
      "17:42:15 |     weight_decay: None\n",
      "17:42:15 |     wrap_memory_encoder: False\n",
      "17:42:15 | Current internal commit: 11ea87027970f68b7d52fb8e6229a7945e0ebe3b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:42:15 | Current fb commit: 11ea87027970f68b7d52fb8e6229a7945e0ebe3b\n",
      "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
      "17:42:15 | creating task(s): interactive\n",
      "17:43:33 | \u001b[33m[ Executing eval mode with a common set of fixed candidates (n = 131438). ]\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 25437984768 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mh:\\My Drive\\github\\nltk-parlai-prototype\\mattheus-parlai-model-test.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mparlai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscripts\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minteractive\u001b[39;00m \u001b[39mimport\u001b[39;00m Interactive\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=3'>4</a>\u001b[0m \u001b[39m# call it with particular args\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=4'>5</a>\u001b[0m Interactive\u001b[39m.\u001b[39;49mmain(\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=5'>6</a>\u001b[0m     \u001b[39m# the model_file is a filename path pointing to a particular model dump.\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=6'>7</a>\u001b[0m     \u001b[39m# Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=7'>8</a>\u001b[0m     \u001b[39m# They'll be automatically downloaded when you ask to use them.\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=8'>9</a>\u001b[0m     \n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=9'>10</a>\u001b[0m     \u001b[39m# model_file='zoo:tutorial_transformer_generator/model'\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=10'>11</a>\u001b[0m     \u001b[39m# model_file='zoo:dodecadialogue/wizard_of_wikipedia_ft/model'\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=11'>12</a>\u001b[0m     \u001b[39m# model_file='zoo:dodecadialogue/light_dialog_ft/model'\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=12'>13</a>\u001b[0m     model_file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mzoo:pretrained_transformers/poly_model_huge_reddit/model\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m# TODO: debug\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=13'>14</a>\u001b[0m     \u001b[39m# model_file='zoo:pretrained_transformers/poly_model_huge_wikito/model' # TODO: debug\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=14'>15</a>\u001b[0m     \u001b[39m# model_file='zoo:pretrained_transformers/model_poly/model' # TODO: debug\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=15'>16</a>\u001b[0m     \u001b[39m# model_file='zoo:dodecadialogue/cornell_movie_ft/model'\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/My%20Drive/github/nltk-parlai-prototype/mattheus-parlai-model-test.ipynb#ch0000001?line=16'>17</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\core\\script.py:127\u001b[0m, in \u001b[0;36mParlaiScript.main\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/script.py?line=124'>125</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_run_args(args)\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/script.py?line=125'>126</a>\u001b[0m \u001b[39melif\u001b[39;00m kwargs:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/script.py?line=126'>127</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_run_kwargs(kwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/script.py?line=127'>128</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/script.py?line=128'>129</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_run_args(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\core\\script.py:92\u001b[0m, in \u001b[0;36mParlaiScript._run_kwargs\u001b[1;34m(cls, kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/script.py?line=89'>90</a>\u001b[0m parser \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_args()\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/script.py?line=90'>91</a>\u001b[0m opt \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39mparse_kwargs(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/script.py?line=91'>92</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_run_from_parser_and_opt(opt, parser)\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\core\\script.py:108\u001b[0m, in \u001b[0;36mParlaiScript._run_from_parser_and_opt\u001b[1;34m(cls, opt, parser)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/script.py?line=105'>106</a>\u001b[0m script \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(opt)\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/script.py?line=106'>107</a>\u001b[0m script\u001b[39m.\u001b[39mparser \u001b[39m=\u001b[39m parser\n\u001b[1;32m--> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/script.py?line=107'>108</a>\u001b[0m \u001b[39mreturn\u001b[39;00m script\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\scripts\\interactive.py:118\u001b[0m, in \u001b[0;36mInteractive.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/scripts/interactive.py?line=116'>117</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/scripts/interactive.py?line=117'>118</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m interactive(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopt)\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\scripts\\interactive.py:93\u001b[0m, in \u001b[0;36minteractive\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/scripts/interactive.py?line=90'>91</a>\u001b[0m \u001b[39m# Show some example dialogs:\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/scripts/interactive.py?line=91'>92</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m world\u001b[39m.\u001b[39mepoch_done():\n\u001b[1;32m---> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/scripts/interactive.py?line=92'>93</a>\u001b[0m     world\u001b[39m.\u001b[39;49mparley()\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/scripts/interactive.py?line=93'>94</a>\u001b[0m     \u001b[39mif\u001b[39;00m world\u001b[39m.\u001b[39mepoch_done() \u001b[39mor\u001b[39;00m world\u001b[39m.\u001b[39mget_total_parleys() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/scripts/interactive.py?line=94'>95</a>\u001b[0m         \u001b[39m# chat was reset with [DONE], [EXIT] or EOF\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/scripts/interactive.py?line=95'>96</a>\u001b[0m         \u001b[39mif\u001b[39;00m world_logger \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\tasks\\interactive\\worlds.py:89\u001b[0m, in \u001b[0;36mInteractiveWorld.parley\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/tasks/interactive/worlds.py?line=86'>87</a>\u001b[0m     agents[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mobserve(validate(context_act))\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/tasks/interactive/worlds.py?line=87'>88</a>\u001b[0m agents[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mobserve(validate(act))\n\u001b[1;32m---> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/tasks/interactive/worlds.py?line=88'>89</a>\u001b[0m acts[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m agents[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mact()\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/tasks/interactive/worlds.py?line=89'>90</a>\u001b[0m agents[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mobserve(validate(acts[\u001b[39m1\u001b[39m]))\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/tasks/interactive/worlds.py?line=90'>91</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_counters()\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\core\\torch_agent.py:2147\u001b[0m, in \u001b[0;36mTorchAgent.act\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2141'>2142</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2142'>2143</a>\u001b[0m \u001b[39mCall batch_act with the singleton batch.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2143'>2144</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2144'>2145</a>\u001b[0m \u001b[39m# BatchWorld handles calling self_observe, but we're in a Hogwild or Interactive\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2145'>2146</a>\u001b[0m \u001b[39m# world, so we need to handle this ourselves.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2146'>2147</a>\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_act([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservation])[\u001b[39m0\u001b[39m]\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2147'>2148</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_observe(response)\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2148'>2149</a>\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\core\\torch_agent.py:2243\u001b[0m, in \u001b[0;36mTorchAgent.batch_act\u001b[1;34m(self, observations)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2238'>2239</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2239'>2240</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2240'>2241</a>\u001b[0m         \u001b[39m# save memory and compute by disabling autograd.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2241'>2242</a>\u001b[0m         \u001b[39m# use `with torch.enable_grad()` to gain back gradients.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2242'>2243</a>\u001b[0m         output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_step(batch)\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2244'>2245</a>\u001b[0m \u001b[39mif\u001b[39;00m output \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2245'>2246</a>\u001b[0m     \u001b[39m# local metrics are automatically matched up\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_agent.py?line=2246'>2247</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmatch_batch(batch_reply, batch\u001b[39m.\u001b[39mvalid_indices, output)\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\core\\torch_ranker_agent.py:522\u001b[0m, in \u001b[0;36mTorchRankerAgent.eval_step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_ranker_agent.py?line=518'>519</a>\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_candidates \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_ranker_agent.py?line=519'>520</a>\u001b[0m         cand_encs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_candidate_encs\n\u001b[1;32m--> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_ranker_agent.py?line=521'>522</a>\u001b[0m scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscore_candidates(batch, cand_vecs, cand_encs\u001b[39m=\u001b[39;49mcand_encs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_ranker_agent.py?line=522'>523</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrank_top_k \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_ranker_agent.py?line=523'>524</a>\u001b[0m     sorted_scores, ranks \u001b[39m=\u001b[39m scores\u001b[39m.\u001b[39mtopk(\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_ranker_agent.py?line=524'>525</a>\u001b[0m         \u001b[39mmin\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrank_top_k, scores\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)), \u001b[39m1\u001b[39m, largest\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/core/torch_ranker_agent.py?line=525'>526</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\agents\\transformer\\polyencoder.py:242\u001b[0m, in \u001b[0;36mPolyencoderAgent.score_candidates\u001b[1;34m(self, batch, cand_vecs, cand_encs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=234'>235</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=235'>236</a>\u001b[0m \u001b[39mScore candidates.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=236'>237</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=237'>238</a>\u001b[0m \u001b[39mThe Poly-encoder encodes the candidate and context independently. Then, the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=238'>239</a>\u001b[0m \u001b[39mmodel applies additional attention before ultimately scoring a candidate.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=239'>240</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=240'>241</a>\u001b[0m ctxt_rep, ctxt_rep_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_ctxt_rep(batch)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=241'>242</a>\u001b[0m cand_rep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_cand_rep(batch, cand_vecs, cand_encs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=242'>243</a>\u001b[0m scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_scores(ctxt_rep, ctxt_rep_mask, cand_rep)\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=243'>244</a>\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\agents\\transformer\\polyencoder.py:215\u001b[0m, in \u001b[0;36mPolyencoderAgent.get_cand_rep\u001b[1;34m(self, batch, cand_vecs, cand_encs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=211'>212</a>\u001b[0m \u001b[39m# bsz x seq len (if batch cands) or num_cands x seq len (if fixed cands)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=212'>213</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=213'>214</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(cand_vecs\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=214'>215</a>\u001b[0m     _, _, cand_rep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(cand_tokens\u001b[39m=\u001b[39;49mcand_vecs\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m))\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=215'>216</a>\u001b[0m     num_cands \u001b[39m=\u001b[39m cand_rep\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)  \u001b[39m# will be bsz if using batch cands\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=216'>217</a>\u001b[0m     cand_rep \u001b[39m=\u001b[39m cand_rep\u001b[39m.\u001b[39mexpand(num_cands, bsz, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\agents\\transformer\\polyencoder.py:581\u001b[0m, in \u001b[0;36mPolyEncoderModule.forward\u001b[1;34m(self, cand_tokens, ctxt_rep, ctxt_rep_mask, cand_rep, **ctxt_inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=556'>557</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=557'>558</a>\u001b[0m \u001b[39mForward pass of the model.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=558'>559</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=577'>578</a>\u001b[0m \u001b[39m    encoded representation of the candidates\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=578'>579</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=579'>580</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ctxt_inputs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m cand_tokens \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=580'>581</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode(cand_tokens\u001b[39m=\u001b[39;49mcand_tokens, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mctxt_inputs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=581'>582</a>\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=582'>583</a>\u001b[0m     ctxt_rep \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ctxt_rep_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m cand_rep \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=583'>584</a>\u001b[0m ):\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=584'>585</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore(ctxt_rep, ctxt_rep_mask, cand_rep)\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\agents\\transformer\\polyencoder.py:466\u001b[0m, in \u001b[0;36mPolyEncoderModule.encode\u001b[1;34m(self, cand_tokens, **ctxt_inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=463'>464</a>\u001b[0m     bsz \u001b[39m=\u001b[39m cand_tokens\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=464'>465</a>\u001b[0m     num_cands \u001b[39m=\u001b[39m cand_tokens\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=465'>466</a>\u001b[0m     cand_embed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_cand(cand_tokens\u001b[39m.\u001b[39;49mview(bsz \u001b[39m*\u001b[39;49m num_cands, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=466'>467</a>\u001b[0m     cand_embed \u001b[39m=\u001b[39m cand_embed\u001b[39m.\u001b[39mview(bsz, num_cands, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/polyencoder.py?line=468'>469</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ctxt_inputs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\agents\\transformer\\modules\\encoder.py:360\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, input, positions, segments, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=348'>349</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=349'>350</a>\u001b[0m \u001b[39mForward pass.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=350'>351</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=356'>357</a>\u001b[0m \u001b[39m    If provided, additionally adds ``segments`` as extra embedding features.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=357'>358</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=358'>359</a>\u001b[0m \u001b[39m# embed input\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=359'>360</a>\u001b[0m tensor, mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_embedding(\u001b[39minput\u001b[39;49m, positions, segments)\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=361'>362</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariant \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mxlm\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariant \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbart\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=362'>363</a>\u001b[0m     tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm_embeddings(tensor)\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\parlai\\agents\\transformer\\modules\\encoder.py:278\u001b[0m, in \u001b[0;36mTransformerEncoder.forward_embedding\u001b[1;34m(self, input, positions, segments)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=270'>271</a>\u001b[0m \u001b[39mif\u001b[39;00m positions\u001b[39m.\u001b[39mmax()\u001b[39m.\u001b[39mitem() \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_positions:\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=271'>272</a>\u001b[0m     warn_once(\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=272'>273</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mYou are inputting a sequence of \u001b[39m\u001b[39m{x}\u001b[39;00m\u001b[39m length, but only have \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=273'>274</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m--n-positions \u001b[39m\u001b[39m{y}\u001b[39;00m\u001b[39m. Set --truncate or increase --n-positions\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=274'>275</a>\u001b[0m             x\u001b[39m=\u001b[39mpositions\u001b[39m.\u001b[39mmax()\u001b[39m.\u001b[39mitem(), y\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_positions\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=275'>276</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=276'>277</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=277'>278</a>\u001b[0m position_embs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mposition_embeddings(positions)\u001b[39m.\u001b[39mexpand_as(tensor)\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=278'>279</a>\u001b[0m tensor \u001b[39m=\u001b[39m tensor \u001b[39m+\u001b[39m position_embs\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/parlai/agents/transformer/modules/encoder.py?line=280'>281</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_segments \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/sparse.py?line=156'>157</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/sparse.py?line=157'>158</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/sparse.py?line=158'>159</a>\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/modules/sparse.py?line=159'>160</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[1;32mc:\\Users\\Mattheus\\anaconda3\\envs\\arp\\lib\\site-packages\\torch\\nn\\functional.py:2183\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/functional.py?line=2176'>2177</a>\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/functional.py?line=2177'>2178</a>\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/functional.py?line=2178'>2179</a>\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/functional.py?line=2179'>2180</a>\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/functional.py?line=2180'>2181</a>\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/functional.py?line=2181'>2182</a>\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Mattheus/anaconda3/envs/arp/lib/site-packages/torch/nn/functional.py?line=2182'>2183</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 25437984768 bytes."
     ]
    }
   ],
   "source": [
    "# Import the Interactive script\n",
    "from parlai.scripts.interactive import Interactive\n",
    "\n",
    "# call it with particular args\n",
    "Interactive.main(\n",
    "    # the model_file is a filename path pointing to a particular model dump.\n",
    "    # Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\n",
    "    # They'll be automatically downloaded when you ask to use them.\n",
    "    \n",
    "    # model_file='zoo:tutorial_transformer_generator/model'\n",
    "    # model_file='zoo:dodecadialogue/wizard_of_wikipedia_ft/model'\n",
    "    # model_file='zoo:dodecadialogue/light_dialog_ft/model'\n",
    "    model_file='zoo:pretrained_transformers/poly_model_huge_reddit/model' # TODO: debug\n",
    "    # model_file='zoo:pretrained_transformers/poly_model_huge_wikito/model' # TODO: debug\n",
    "    # model_file='zoo:pretrained_transformers/model_poly/model' # TODO: debug\n",
    "    # model_file='zoo:dodecadialogue/cornell_movie_ft/model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parlai.utils.io import PathManager\n",
    "\n",
    "cand_path = \"C:\\\\Users\\\\Mattheus\\\\anaconda3\\\\envs\\\\arp\\\\Lib\\\\site-packages\\\\data\\\\models\\\\pretrained_transformers\\\\convai_trainset_cands.txt\"\n",
    "\n",
    "with PathManager.open(cand_path, 'r', encoding='utf-8') as f:\n",
    "    cands = [line.strip() for line in f.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "490cb818d5e0c492e443978645a5675868909fcceb9d81b47b9d2e4a923617cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('arp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
