{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZHb4miqDC4EL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ad3b72-6c45-4816-d83d-3e0e19e5fd83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iymbr6f_C4EN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c7c2aa0-5c5b-42a6-f840-ef5193976267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 10.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 248 kB 45.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 125 kB 42.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 46.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 175 kB 72.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 49.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 55.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 235 kB 59.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 749 kB 54.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 342 kB 57.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 208 kB 59.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 547 kB 51.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 44.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 48 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 67.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 40 kB 6.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 44.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 50.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 62.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 95 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 60.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 56.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 136 kB 52.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 51.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 53.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 110 kB 61.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 121 kB 55.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 100 kB 11.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 59.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 44.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 951 kB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 8.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25h  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docformatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for untokenize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q parlai\n",
        "!pip install -q subword_nmt # extra requirement we need for this tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I0FdTKEbC4EO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475dcb43-5476-436a-e8d6-23ca791d5d8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:02:05 | building data: /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/dodecadialogue_v2.tgz\n",
            "11:02:05 | Downloading http://parl.ai/downloads/_models/dodecadialogue/dodecadialogue_v2.tgz to /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/dodecadialogue_v2.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading dodecadialogue_v2.tgz: 100%|██████████| 396k/396k [00:00<00:00, 844kB/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:02:05 | building data: /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/daily_dialog_ft/daily_dialog_ft.tgz\n",
            "11:02:05 | Downloading http://parl.ai/downloads/_models/dodecadialogue/daily_dialog_ft/daily_dialog_ft.tgz to /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/daily_dialog_ft/daily_dialog_ft.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Downloading daily_dialog_ft.tgz: 100%|██████████| 959M/959M [00:15<00:00, 62.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:02:41 | \u001b[33mOverriding opt[\"model_file\"] to /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/daily_dialog_ft/model (previously: data/models/dodecadialogue/daily_dialog/model)\u001b[0m\n",
            "11:02:41 | \u001b[33mLoading model with `--beam-block-full-context false`\u001b[0m\n",
            "11:02:42 | loading dictionary from /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/daily_dialog_ft/model.dict\n",
            "11:02:42 | num words = 54946\n",
            "11:02:42 | ImageSeq2seq: full interactive mode on.\n",
            "11:02:43 | \u001b[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001b[0m\n",
            "11:02:44 | Total parameters: 88,559,104 (88,559,104 trainable)\n",
            "11:02:44 | Loading existing model params from /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/daily_dialog_ft/model\n",
            "11:02:45 | Opt:\n",
            "11:02:45 |     activation: gelu\n",
            "11:02:45 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "11:02:45 |     adam_eps: 1e-08\n",
            "11:02:45 |     add_p1_after_newln: False\n",
            "11:02:45 |     aggregate_micro: False\n",
            "11:02:45 |     allow_missing_init_opts: False\n",
            "11:02:45 |     attention_dropout: 0.0\n",
            "11:02:45 |     batch_length_range: 5\n",
            "11:02:45 |     batch_sort_cache_type: pop\n",
            "11:02:45 |     batch_sort_field: text\n",
            "11:02:45 |     batchsize: 16\n",
            "11:02:45 |     beam_block_full_context: False\n",
            "11:02:45 |     beam_block_list_filename: None\n",
            "11:02:45 |     beam_block_ngram: -1\n",
            "11:02:45 |     beam_context_block_ngram: -1\n",
            "11:02:45 |     beam_delay: 30\n",
            "11:02:45 |     beam_length_penalty: 0.65\n",
            "11:02:45 |     beam_min_length: 1\n",
            "11:02:45 |     beam_size: 1\n",
            "11:02:45 |     betas: '[0.9, 0.999]'\n",
            "11:02:45 |     bpe_add_prefix_space: None\n",
            "11:02:45 |     bpe_debug: False\n",
            "11:02:45 |     bpe_dropout: None\n",
            "11:02:45 |     bpe_merge: None\n",
            "11:02:45 |     bpe_vocab: None\n",
            "11:02:45 |     checkpoint_activations: False\n",
            "11:02:45 |     compute_tokenized_bleu: False\n",
            "11:02:45 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "11:02:45 |     datatype: train\n",
            "11:02:45 |     delimiter: '\\n'\n",
            "11:02:45 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "11:02:45 |     dict_endtoken: __end__\n",
            "11:02:45 |     dict_file: /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/daily_dialog_ft/model.dict\n",
            "11:02:45 |     dict_include_test: False\n",
            "11:02:45 |     dict_include_valid: False\n",
            "11:02:45 |     dict_initpath: None\n",
            "11:02:45 |     dict_language: english\n",
            "11:02:45 |     dict_loaded: True\n",
            "11:02:45 |     dict_lower: True\n",
            "11:02:45 |     dict_max_ngram_size: -1\n",
            "11:02:45 |     dict_maxexs: -1\n",
            "11:02:45 |     dict_maxtokens: -1\n",
            "11:02:45 |     dict_minfreq: 0\n",
            "11:02:45 |     dict_nulltoken: __null__\n",
            "11:02:45 |     dict_starttoken: __start__\n",
            "11:02:45 |     dict_textfields: text,labels\n",
            "11:02:45 |     dict_tokenizer: bpe\n",
            "11:02:45 |     dict_unktoken: __unk__\n",
            "11:02:45 |     display_add_fields: \n",
            "11:02:45 |     display_examples: False\n",
            "11:02:45 |     display_prettify: False\n",
            "11:02:45 |     download_path: None\n",
            "11:02:45 |     dropout: 0.1\n",
            "11:02:45 |     dynamic_batching: None\n",
            "11:02:45 |     embedding_projection: random\n",
            "11:02:45 |     embedding_size: 512\n",
            "11:02:45 |     embedding_type: random\n",
            "11:02:45 |     embeddings_scale: True\n",
            "11:02:45 |     eval_batchsize: None\n",
            "11:02:45 |     evaltask: None\n",
            "11:02:45 |     ffn_size: 2048\n",
            "11:02:45 |     force_fp16_tokens: False\n",
            "11:02:45 |     fp16: False\n",
            "11:02:45 |     fp16_impl: safe\n",
            "11:02:45 |     gpu: -1\n",
            "11:02:45 |     gradient_clip: 0.1\n",
            "11:02:45 |     hide_labels: False\n",
            "11:02:45 |     history_add_global_end_token: None\n",
            "11:02:45 |     history_reversed: False\n",
            "11:02:45 |     history_size: -1\n",
            "11:02:45 |     image_cropsize: 224\n",
            "11:02:45 |     image_encoder_num_layers: 1\n",
            "11:02:45 |     image_features_dim: 2048\n",
            "11:02:45 |     image_fusion_type: late\n",
            "11:02:45 |     image_mode: no_image_model\n",
            "11:02:45 |     image_size: 256\n",
            "11:02:45 |     include_image_token: True\n",
            "11:02:45 |     inference: greedy\n",
            "11:02:45 |     init_model: data/models/dodecadialogue/base_model/model\n",
            "11:02:45 |     init_opt: None\n",
            "11:02:45 |     interactive_mode: True\n",
            "11:02:45 |     interactive_task: True\n",
            "11:02:45 |     invsqrt_lr_decay_gamma: -1\n",
            "11:02:45 |     is_debug: False\n",
            "11:02:45 |     label_truncate: 128\n",
            "11:02:45 |     learn_positional_embeddings: True\n",
            "11:02:45 |     learningrate: 1e-07\n",
            "11:02:45 |     local_human_candidates_file: None\n",
            "11:02:45 |     log_every_n_secs: 10.0\n",
            "11:02:45 |     log_keep_fields: all\n",
            "11:02:45 |     loglevel: info\n",
            "11:02:45 |     lr_scheduler: reduceonplateau\n",
            "11:02:45 |     lr_scheduler_decay: 0.5\n",
            "11:02:45 |     lr_scheduler_patience: 3\n",
            "11:02:45 |     max_train_time: 84600.0\n",
            "11:02:45 |     metrics: default\n",
            "11:02:45 |     model: image_seq2seq\n",
            "11:02:45 |     model_file: /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/daily_dialog_ft/model\n",
            "11:02:45 |     model_parallel: False\n",
            "11:02:45 |     momentum: 0\n",
            "11:02:45 |     multitask_weights: [1]\n",
            "11:02:45 |     n_decoder_layers: -1\n",
            "11:02:45 |     n_encoder_layers: -1\n",
            "11:02:45 |     n_heads: 16\n",
            "11:02:45 |     n_image_channels: 1\n",
            "11:02:45 |     n_image_tokens: 1\n",
            "11:02:45 |     n_layers: 8\n",
            "11:02:45 |     n_positions: 512\n",
            "11:02:45 |     n_segments: 0\n",
            "11:02:45 |     nesterov: True\n",
            "11:02:45 |     no_cuda: False\n",
            "11:02:45 |     num_epochs: -1\n",
            "11:02:45 |     numthreads: 1\n",
            "11:02:45 |     numworkers: 4\n",
            "11:02:45 |     nus: [0.7]\n",
            "11:02:45 |     optimizer: adamax\n",
            "11:02:45 |     outfile: \n",
            "11:02:45 |     output_scaling: 1.0\n",
            "11:02:45 |     override: \"{'model_file': '/usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/daily_dialog_ft/model'}\"\n",
            "11:02:45 |     parlai_home: /checkpoint/kshuster/projects/parlall/parlall_MT_plus_FT/parlall_MT_plus_FT_sweep1_Tue_Oct_29/ParlAI\n",
            "11:02:45 |     person_tokens: False\n",
            "11:02:45 |     pytorch_context_length: -1\n",
            "11:02:45 |     pytorch_datapath: None\n",
            "11:02:45 |     pytorch_include_labels: True\n",
            "11:02:45 |     pytorch_preprocess: False\n",
            "11:02:45 |     pytorch_teacher_batch_sort: False\n",
            "11:02:45 |     pytorch_teacher_dataset: None\n",
            "11:02:45 |     pytorch_teacher_task: None\n",
            "11:02:45 |     rank_candidates: False\n",
            "11:02:45 |     relu_dropout: 0.0\n",
            "11:02:45 |     save_after_valid: True\n",
            "11:02:45 |     save_every_n_secs: -1\n",
            "11:02:45 |     save_format: conversations\n",
            "11:02:45 |     share_word_embeddings: True\n",
            "11:02:45 |     short_final_eval: False\n",
            "11:02:45 |     show_advanced_args: False\n",
            "11:02:45 |     shuffle: False\n",
            "11:02:45 |     single_turn: False\n",
            "11:02:45 |     skip_generation: True\n",
            "11:02:45 |     special_tok_lst: None\n",
            "11:02:45 |     split_lines: False\n",
            "11:02:45 |     starttime: Oct29_07-56\n",
            "11:02:45 |     task: dailydialog\n",
            "11:02:45 |     temperature: 1.0\n",
            "11:02:45 |     tensorboard_log: False\n",
            "11:02:45 |     text_truncate: 512\n",
            "11:02:45 |     topk: 10\n",
            "11:02:45 |     topp: 0.9\n",
            "11:02:45 |     truncate: -1\n",
            "11:02:45 |     update_freq: 1\n",
            "11:02:45 |     use_reply: label\n",
            "11:02:45 |     validation_cutoff: 1.0\n",
            "11:02:45 |     validation_every_n_epochs: -1\n",
            "11:02:45 |     validation_every_n_secs: 3600.0\n",
            "11:02:45 |     validation_max_exs: -1\n",
            "11:02:45 |     validation_metric: ppl\n",
            "11:02:45 |     validation_metric_mode: min\n",
            "11:02:45 |     validation_patience: 10\n",
            "11:02:45 |     validation_share_agent: False\n",
            "11:02:45 |     variant: xlm\n",
            "11:02:45 |     verbose: False\n",
            "11:02:45 |     warmup_rate: 0.0001\n",
            "11:02:45 |     warmup_updates: 2000\n",
            "11:02:45 |     weight_decay: None\n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "11:02:46 | creating task(s): interactive\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m How are you\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mfine , thank you . and you ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Have you taken your medicine?\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1myes , i have .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Do you need to use the toilet\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mno , i don ' t need to .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m what is your favourite colour\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi like red .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m when is your birthday\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mtoday .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m are you hungry\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1myes , i am .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m do you feel comfortable with the temperature\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1myes , i think so .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [EXIT]\n",
            "CHAT DONE \n"
          ]
        }
      ],
      "source": [
        "import parlai\n",
        "\n",
        "# Import the Interactive script\n",
        "from parlai.scripts.interactive import Interactive\n",
        "\n",
        "# call it with particular args\n",
        "Interactive.main(\n",
        "    # the model_file is a filename path pointing to a particular model dump.\n",
        "    # Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\n",
        "    # They'll be automatically downloaded when you ask to use them.\n",
        "    model_file='zoo:dodecadialogue/daily_dialog_ft/model'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x84CZ5F_C4EO",
        "outputId": "f8237af5-3a3a-4ad0-c3b6-469126b0980f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:05:14 | building data: /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/eli5_ft/eli5_ft.tgz\n",
            "11:05:14 | Downloading http://parl.ai/downloads/_models/dodecadialogue/eli5_ft/eli5_ft.tgz to /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/eli5_ft/eli5_ft.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading eli5_ft.tgz: 100%|██████████| 963M/963M [00:17<00:00, 54.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:05:53 | \u001b[33mOverriding opt[\"model_file\"] to /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/eli5_ft/model (previously: data/models/dodecadialogue/eli5/model)\u001b[0m\n",
            "11:05:53 | loading dictionary from /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/eli5_ft/model.dict\n",
            "11:05:53 | num words = 54946\n",
            "11:05:53 | ImageSeq2seq: full interactive mode on.\n",
            "11:05:55 | Total parameters: 88,559,104 (88,559,104 trainable)\n",
            "11:05:55 | Loading existing model params from /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/eli5_ft/model\n",
            "11:05:56 | Opt:\n",
            "11:05:56 |     activation: gelu\n",
            "11:05:56 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "11:05:56 |     adam_eps: 1e-08\n",
            "11:05:56 |     add_p1_after_newln: False\n",
            "11:05:56 |     aggregate_micro: False\n",
            "11:05:56 |     allow_missing_init_opts: False\n",
            "11:05:56 |     attention_dropout: 0.0\n",
            "11:05:56 |     batch_length_range: 5\n",
            "11:05:56 |     batch_sort_cache_type: pop\n",
            "11:05:56 |     batch_sort_field: text\n",
            "11:05:56 |     batchsize: 24\n",
            "11:05:56 |     beam_block_full_context: False\n",
            "11:05:56 |     beam_block_list_filename: None\n",
            "11:05:56 |     beam_block_ngram: -1\n",
            "11:05:56 |     beam_context_block_ngram: -1\n",
            "11:05:56 |     beam_delay: 30\n",
            "11:05:56 |     beam_length_penalty: 0.65\n",
            "11:05:56 |     beam_min_length: 1\n",
            "11:05:56 |     beam_size: 1\n",
            "11:05:56 |     betas: '[0.9, 0.999]'\n",
            "11:05:56 |     bpe_add_prefix_space: None\n",
            "11:05:56 |     bpe_debug: False\n",
            "11:05:56 |     bpe_dropout: None\n",
            "11:05:56 |     bpe_merge: None\n",
            "11:05:56 |     bpe_vocab: None\n",
            "11:05:56 |     checkpoint_activations: False\n",
            "11:05:56 |     compute_tokenized_bleu: False\n",
            "11:05:56 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "11:05:56 |     datatype: train\n",
            "11:05:56 |     delimiter: '\\n'\n",
            "11:05:56 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "11:05:56 |     dict_endtoken: __end__\n",
            "11:05:56 |     dict_file: /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/eli5_ft/model.dict\n",
            "11:05:56 |     dict_include_test: False\n",
            "11:05:56 |     dict_include_valid: False\n",
            "11:05:56 |     dict_initpath: None\n",
            "11:05:56 |     dict_language: english\n",
            "11:05:56 |     dict_loaded: True\n",
            "11:05:56 |     dict_lower: True\n",
            "11:05:56 |     dict_max_ngram_size: -1\n",
            "11:05:56 |     dict_maxexs: -1\n",
            "11:05:56 |     dict_maxtokens: -1\n",
            "11:05:56 |     dict_minfreq: 0\n",
            "11:05:56 |     dict_nulltoken: __null__\n",
            "11:05:56 |     dict_starttoken: __start__\n",
            "11:05:56 |     dict_textfields: text,labels\n",
            "11:05:56 |     dict_tokenizer: bpe\n",
            "11:05:56 |     dict_unktoken: __unk__\n",
            "11:05:56 |     display_add_fields: \n",
            "11:05:56 |     display_examples: False\n",
            "11:05:56 |     display_prettify: False\n",
            "11:05:56 |     download_path: None\n",
            "11:05:56 |     dropout: 0.1\n",
            "11:05:56 |     dynamic_batching: None\n",
            "11:05:56 |     embedding_projection: random\n",
            "11:05:56 |     embedding_size: 512\n",
            "11:05:56 |     embedding_type: random\n",
            "11:05:56 |     embeddings_scale: True\n",
            "11:05:56 |     eval_batchsize: None\n",
            "11:05:56 |     evaltask: None\n",
            "11:05:56 |     ffn_size: 2048\n",
            "11:05:56 |     force_fp16_tokens: False\n",
            "11:05:56 |     fp16: False\n",
            "11:05:56 |     fp16_impl: safe\n",
            "11:05:56 |     gpu: -1\n",
            "11:05:56 |     gradient_clip: 0.1\n",
            "11:05:56 |     hide_labels: False\n",
            "11:05:56 |     history_add_global_end_token: None\n",
            "11:05:56 |     history_reversed: False\n",
            "11:05:56 |     history_size: -1\n",
            "11:05:56 |     image_cropsize: 224\n",
            "11:05:56 |     image_encoder_num_layers: 1\n",
            "11:05:56 |     image_features_dim: 2048\n",
            "11:05:56 |     image_fusion_type: late\n",
            "11:05:56 |     image_mode: no_image_model\n",
            "11:05:56 |     image_size: 256\n",
            "11:05:56 |     include_image_token: True\n",
            "11:05:56 |     inference: greedy\n",
            "11:05:56 |     init_model: data/models/dodecadialogue/base_model/model\n",
            "11:05:56 |     init_opt: None\n",
            "11:05:56 |     interactive_mode: True\n",
            "11:05:56 |     interactive_task: True\n",
            "11:05:56 |     invsqrt_lr_decay_gamma: -1\n",
            "11:05:56 |     is_debug: False\n",
            "11:05:56 |     knowledge: True\n",
            "11:05:56 |     label_truncate: 256\n",
            "11:05:56 |     learn_positional_embeddings: True\n",
            "11:05:56 |     learningrate: 1e-08\n",
            "11:05:56 |     local_human_candidates_file: None\n",
            "11:05:56 |     log_every_n_secs: 10.0\n",
            "11:05:56 |     log_keep_fields: all\n",
            "11:05:56 |     loglevel: info\n",
            "11:05:56 |     lr_scheduler: reduceonplateau\n",
            "11:05:56 |     lr_scheduler_decay: 0.5\n",
            "11:05:56 |     lr_scheduler_patience: 3\n",
            "11:05:56 |     max_train_time: 257400.0\n",
            "11:05:56 |     metrics: default\n",
            "11:05:56 |     model: image_seq2seq\n",
            "11:05:56 |     model_file: /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/eli5_ft/model\n",
            "11:05:56 |     model_parallel: False\n",
            "11:05:56 |     momentum: 0\n",
            "11:05:56 |     multitask_weights: [1]\n",
            "11:05:56 |     n_decoder_layers: -1\n",
            "11:05:56 |     n_encoder_layers: -1\n",
            "11:05:56 |     n_heads: 16\n",
            "11:05:56 |     n_image_channels: 1\n",
            "11:05:56 |     n_image_tokens: 1\n",
            "11:05:56 |     n_layers: 8\n",
            "11:05:56 |     n_positions: 512\n",
            "11:05:56 |     n_segments: 0\n",
            "11:05:56 |     nesterov: True\n",
            "11:05:56 |     no_cuda: False\n",
            "11:05:56 |     num_epochs: -1\n",
            "11:05:56 |     numthreads: 1\n",
            "11:05:56 |     numworkers: 4\n",
            "11:05:56 |     nus: [0.7]\n",
            "11:05:56 |     optimizer: adamax\n",
            "11:05:56 |     outfile: \n",
            "11:05:56 |     output_scaling: 1.0\n",
            "11:05:56 |     override: \"{'model_file': '/usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/eli5_ft/model'}\"\n",
            "11:05:56 |     parlai_home: /checkpoint/kshuster/projects/parlall/parlall_MT_plus_FT/parlall_MT_upweight_plus_FT_sweep25_Mon_Nov_18/ParlAI\n",
            "11:05:56 |     person_tokens: False\n",
            "11:05:56 |     pytorch_context_length: -1\n",
            "11:05:56 |     pytorch_datapath: None\n",
            "11:05:56 |     pytorch_include_labels: True\n",
            "11:05:56 |     pytorch_preprocess: False\n",
            "11:05:56 |     pytorch_teacher_batch_sort: False\n",
            "11:05:56 |     pytorch_teacher_dataset: None\n",
            "11:05:56 |     pytorch_teacher_task: None\n",
            "11:05:56 |     rank_candidates: False\n",
            "11:05:56 |     relu_dropout: 0.0\n",
            "11:05:56 |     save_after_valid: True\n",
            "11:05:56 |     save_every_n_secs: -1\n",
            "11:05:56 |     save_format: conversations\n",
            "11:05:56 |     share_word_embeddings: True\n",
            "11:05:56 |     short_final_eval: False\n",
            "11:05:56 |     show_advanced_args: False\n",
            "11:05:56 |     shuffle: False\n",
            "11:05:56 |     single_turn: False\n",
            "11:05:56 |     skip_generation: True\n",
            "11:05:56 |     special_tok_lst: None\n",
            "11:05:56 |     split_lines: False\n",
            "11:05:56 |     starttime: Nov18_14-10\n",
            "11:05:56 |     task: internal:eli5\n",
            "11:05:56 |     temperature: 1.0\n",
            "11:05:56 |     tensorboard_log: False\n",
            "11:05:56 |     text_truncate: 512\n",
            "11:05:56 |     topk: 10\n",
            "11:05:56 |     topp: 0.9\n",
            "11:05:56 |     truncate: -1\n",
            "11:05:56 |     update_freq: 1\n",
            "11:05:56 |     use_reply: label\n",
            "11:05:56 |     validation_cutoff: 1.0\n",
            "11:05:56 |     validation_every_n_epochs: -1\n",
            "11:05:56 |     validation_every_n_secs: 3600.0\n",
            "11:05:56 |     validation_max_exs: -1\n",
            "11:05:56 |     validation_metric: ppl\n",
            "11:05:56 |     validation_metric_mode: min\n",
            "11:05:56 |     validation_patience: 10\n",
            "11:05:56 |     validation_share_agent: False\n",
            "11:05:56 |     variant: xlm\n",
            "11:05:56 |     verbose: False\n",
            "11:05:56 |     warmup_rate: 0.0001\n",
            "11:05:56 |     warmup_updates: 2000\n",
            "11:05:56 |     weight_decay: None\n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "11:05:57 | creating task(s): interactive\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m how are you\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m good . how are you ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m have you taken your medicine\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1myes . i ' ve taken it for a few days .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m do you need to use the toilet\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mno . i ' m fine .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m what's your favourite color\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi like blue .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m when is your birthday\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mit ' s the 21st .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m are you hungry\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1myes . i ' m hungry .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m do you feel comfortable with the temperature\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1myes . i ' m comfortable .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [EXIT]\n",
            "CHAT DONE \n"
          ]
        }
      ],
      "source": [
        "# call it with particular args\n",
        "Interactive.main(\n",
        "    # the model_file is a filename path pointing to a particular model dump.\n",
        "    # Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\n",
        "    # They'll be automatically downloaded when you ask to use them.\n",
        "    model_file='zoo:dodecadialogue/eli5_ft/model'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# call it with particular args\n",
        "Interactive.main(\n",
        "    # the model_file is a filename path pointing to a particular model dump.\n",
        "    # Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\n",
        "    # They'll be automatically downloaded when you ask to use them.\n",
        "    model_file='zoo:dodecadialogue/empathetic_dialogues_ft/model'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztPDzQJsAa1x",
        "outputId": "c101949b-49b0-4a62-e49f-1195c44e1a4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:08:32 | building data: /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/empathetic_dialogues_ft/empathetic_dialogues_ft.tgz\n",
            "11:08:32 | Downloading http://parl.ai/downloads/_models/dodecadialogue/empathetic_dialogues_ft/empathetic_dialogues_ft.tgz to /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/empathetic_dialogues_ft/empathetic_dialogues_ft.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading empathetic_dialogues_ft.tgz: 100%|██████████| 956M/956M [00:16<00:00, 57.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:09:10 | \u001b[33mOverriding opt[\"model_file\"] to /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/empathetic_dialogues_ft/model (previously: data/models/dodecadialogue/empathetic_dialogues/model)\u001b[0m\n",
            "11:09:10 | loading dictionary from /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/empathetic_dialogues_ft/model.dict\n",
            "11:09:10 | num words = 54946\n",
            "11:09:10 | ImageSeq2seq: full interactive mode on.\n",
            "11:09:12 | Total parameters: 88,559,104 (88,559,104 trainable)\n",
            "11:09:12 | Loading existing model params from /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/empathetic_dialogues_ft/model\n",
            "11:09:13 | Opt:\n",
            "11:09:13 |     activation: gelu\n",
            "11:09:13 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "11:09:13 |     adam_eps: 1e-08\n",
            "11:09:13 |     add_p1_after_newln: False\n",
            "11:09:13 |     aggregate_micro: False\n",
            "11:09:13 |     allow_missing_init_opts: False\n",
            "11:09:13 |     attention_dropout: 0.0\n",
            "11:09:13 |     batch_length_range: 5\n",
            "11:09:13 |     batch_sort_cache_type: pop\n",
            "11:09:13 |     batch_sort_field: text\n",
            "11:09:13 |     batchsize: 16\n",
            "11:09:13 |     beam_block_full_context: False\n",
            "11:09:13 |     beam_block_list_filename: None\n",
            "11:09:13 |     beam_block_ngram: -1\n",
            "11:09:13 |     beam_context_block_ngram: -1\n",
            "11:09:13 |     beam_delay: 30\n",
            "11:09:13 |     beam_length_penalty: 0.65\n",
            "11:09:13 |     beam_min_length: 1\n",
            "11:09:13 |     beam_size: 1\n",
            "11:09:13 |     betas: '[0.9, 0.999]'\n",
            "11:09:13 |     bpe_add_prefix_space: None\n",
            "11:09:13 |     bpe_debug: False\n",
            "11:09:13 |     bpe_dropout: None\n",
            "11:09:13 |     bpe_merge: None\n",
            "11:09:13 |     bpe_vocab: None\n",
            "11:09:13 |     checkpoint_activations: False\n",
            "11:09:13 |     compute_tokenized_bleu: False\n",
            "11:09:13 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "11:09:13 |     datatype: train\n",
            "11:09:13 |     delimiter: '\\n'\n",
            "11:09:13 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "11:09:13 |     dict_endtoken: __end__\n",
            "11:09:13 |     dict_file: /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/empathetic_dialogues_ft/model.dict\n",
            "11:09:13 |     dict_include_test: False\n",
            "11:09:13 |     dict_include_valid: False\n",
            "11:09:13 |     dict_initpath: None\n",
            "11:09:13 |     dict_language: english\n",
            "11:09:13 |     dict_loaded: True\n",
            "11:09:13 |     dict_lower: True\n",
            "11:09:13 |     dict_max_ngram_size: -1\n",
            "11:09:13 |     dict_maxexs: -1\n",
            "11:09:13 |     dict_maxtokens: -1\n",
            "11:09:13 |     dict_minfreq: 0\n",
            "11:09:13 |     dict_nulltoken: __null__\n",
            "11:09:13 |     dict_starttoken: __start__\n",
            "11:09:13 |     dict_textfields: text,labels\n",
            "11:09:13 |     dict_tokenizer: bpe\n",
            "11:09:13 |     dict_unktoken: __unk__\n",
            "11:09:13 |     display_add_fields: \n",
            "11:09:13 |     display_examples: False\n",
            "11:09:13 |     display_prettify: False\n",
            "11:09:13 |     download_path: None\n",
            "11:09:13 |     dropout: 0.1\n",
            "11:09:13 |     dynamic_batching: None\n",
            "11:09:13 |     embedding_projection: random\n",
            "11:09:13 |     embedding_size: 512\n",
            "11:09:13 |     embedding_type: random\n",
            "11:09:13 |     embeddings_scale: True\n",
            "11:09:13 |     eval_batchsize: None\n",
            "11:09:13 |     evaltask: None\n",
            "11:09:13 |     ffn_size: 2048\n",
            "11:09:13 |     force_fp16_tokens: False\n",
            "11:09:13 |     fp16: False\n",
            "11:09:13 |     fp16_impl: safe\n",
            "11:09:13 |     gpu: -1\n",
            "11:09:13 |     gradient_clip: 0.1\n",
            "11:09:13 |     hide_labels: False\n",
            "11:09:13 |     history_add_global_end_token: None\n",
            "11:09:13 |     history_reversed: False\n",
            "11:09:13 |     history_size: -1\n",
            "11:09:13 |     image_cropsize: 224\n",
            "11:09:13 |     image_encoder_num_layers: 1\n",
            "11:09:13 |     image_features_dim: 2048\n",
            "11:09:13 |     image_fusion_type: late\n",
            "11:09:13 |     image_mode: no_image_model\n",
            "11:09:13 |     image_size: 256\n",
            "11:09:13 |     include_image_token: True\n",
            "11:09:13 |     inference: greedy\n",
            "11:09:13 |     init_model: data/models/dodecadialogue/base_model/model\n",
            "11:09:13 |     init_opt: None\n",
            "11:09:13 |     interactive_mode: True\n",
            "11:09:13 |     interactive_task: True\n",
            "11:09:13 |     invsqrt_lr_decay_gamma: -1\n",
            "11:09:13 |     is_debug: False\n",
            "11:09:13 |     label_truncate: 128\n",
            "11:09:13 |     learn_positional_embeddings: True\n",
            "11:09:13 |     learningrate: 1e-07\n",
            "11:09:13 |     local_human_candidates_file: None\n",
            "11:09:13 |     log_every_n_secs: 10.0\n",
            "11:09:13 |     log_keep_fields: all\n",
            "11:09:13 |     loglevel: info\n",
            "11:09:13 |     lr_scheduler: reduceonplateau\n",
            "11:09:13 |     lr_scheduler_decay: 0.5\n",
            "11:09:13 |     lr_scheduler_patience: 3\n",
            "11:09:13 |     max_train_time: 84600.0\n",
            "11:09:13 |     metrics: default\n",
            "11:09:13 |     model: image_seq2seq\n",
            "11:09:13 |     model_file: /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/empathetic_dialogues_ft/model\n",
            "11:09:13 |     model_parallel: False\n",
            "11:09:13 |     momentum: 0\n",
            "11:09:13 |     multitask_weights: [1]\n",
            "11:09:13 |     n_decoder_layers: -1\n",
            "11:09:13 |     n_encoder_layers: -1\n",
            "11:09:13 |     n_heads: 16\n",
            "11:09:13 |     n_image_channels: 1\n",
            "11:09:13 |     n_image_tokens: 1\n",
            "11:09:13 |     n_layers: 8\n",
            "11:09:13 |     n_positions: 512\n",
            "11:09:13 |     n_segments: 0\n",
            "11:09:13 |     nesterov: True\n",
            "11:09:14 |     no_cuda: False\n",
            "11:09:14 |     num_epochs: -1\n",
            "11:09:14 |     numthreads: 1\n",
            "11:09:14 |     numworkers: 4\n",
            "11:09:14 |     nus: [0.7]\n",
            "11:09:14 |     optimizer: adamax\n",
            "11:09:14 |     outfile: \n",
            "11:09:14 |     output_scaling: 1.0\n",
            "11:09:14 |     override: \"{'model_file': '/usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/empathetic_dialogues_ft/model'}\"\n",
            "11:09:14 |     parlai_home: /checkpoint/kshuster/projects/parlall/parlall_MT_plus_FT/parlall_MT_plus_FT_sweep1_Tue_Oct_29/ParlAI\n",
            "11:09:14 |     person_tokens: False\n",
            "11:09:14 |     pytorch_context_length: -1\n",
            "11:09:14 |     pytorch_datapath: None\n",
            "11:09:14 |     pytorch_include_labels: True\n",
            "11:09:14 |     pytorch_preprocess: False\n",
            "11:09:14 |     pytorch_teacher_batch_sort: False\n",
            "11:09:14 |     pytorch_teacher_dataset: None\n",
            "11:09:14 |     pytorch_teacher_task: None\n",
            "11:09:14 |     rank_candidates: False\n",
            "11:09:14 |     relu_dropout: 0.0\n",
            "11:09:14 |     save_after_valid: True\n",
            "11:09:14 |     save_every_n_secs: -1\n",
            "11:09:14 |     save_format: conversations\n",
            "11:09:14 |     share_word_embeddings: True\n",
            "11:09:14 |     short_final_eval: False\n",
            "11:09:14 |     show_advanced_args: False\n",
            "11:09:14 |     shuffle: False\n",
            "11:09:14 |     single_turn: False\n",
            "11:09:14 |     skip_generation: True\n",
            "11:09:14 |     special_tok_lst: None\n",
            "11:09:14 |     split_lines: False\n",
            "11:09:14 |     starttime: Oct29_07-56\n",
            "11:09:14 |     task: empathetic_dialogues\n",
            "11:09:14 |     temperature: 1.0\n",
            "11:09:14 |     tensorboard_log: False\n",
            "11:09:14 |     text_truncate: 512\n",
            "11:09:14 |     topk: 10\n",
            "11:09:14 |     topp: 0.9\n",
            "11:09:14 |     truncate: -1\n",
            "11:09:14 |     update_freq: 1\n",
            "11:09:14 |     use_reply: label\n",
            "11:09:14 |     validation_cutoff: 1.0\n",
            "11:09:14 |     validation_every_n_epochs: -1\n",
            "11:09:14 |     validation_every_n_secs: 3600.0\n",
            "11:09:14 |     validation_max_exs: -1\n",
            "11:09:14 |     validation_metric: ppl\n",
            "11:09:14 |     validation_metric_mode: min\n",
            "11:09:14 |     validation_patience: 10\n",
            "11:09:14 |     validation_share_agent: False\n",
            "11:09:14 |     variant: xlm\n",
            "11:09:14 |     verbose: False\n",
            "11:09:14 |     warmup_rate: 0.0001\n",
            "11:09:14 |     warmup_updates: 2000\n",
            "11:09:14 |     weight_decay: None\n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "11:09:14 | creating task(s): interactive\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m How are you\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m good . how are you ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Have you taken your medicine\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi have . i ' m feeling better .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m do you need to use the toilet?\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mno . i don ' t need to .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m what is your favourite colour?\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi don ' t really have a favorite .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m when is your birthday?\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mit ' s on the 10th .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m are you hungry?\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m not hungry .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m do you feel comfortable with the tempreture\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi don ' t think so .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [EXIT]\n",
            "CHAT DONE \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# call it with particular args\n",
        "Interactive.main(\n",
        "    # the model_file is a filename path pointing to a particular model dump.\n",
        "    # Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\n",
        "    # They'll be automatically downloaded when you ask to use them.\n",
        "    model_file='zoo:dodecadialogue/twitter_ft/model'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y24Mk_D8AbA7",
        "outputId": "be2882e4-3648-4ba3-80fe-553021c81aba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:11:01 | building data: /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/twitter_ft/twitter_ft.tgz\n",
            "11:11:01 | Downloading http://parl.ai/downloads/_models/dodecadialogue/twitter_ft/twitter_ft.tgz to /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/twitter_ft/twitter_ft.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading twitter_ft.tgz: 100%|██████████| 960M/960M [00:15<00:00, 63.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:11:37 | \u001b[33mOverriding opt[\"model_file\"] to /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/twitter_ft/model (previously: data/models/dodecadialogue/twitter/model)\u001b[0m\n",
            "11:11:37 | loading dictionary from /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/twitter_ft/model.dict\n",
            "11:11:37 | num words = 54946\n",
            "11:11:37 | ImageSeq2seq: full interactive mode on.\n",
            "11:11:39 | Total parameters: 88,559,104 (88,559,104 trainable)\n",
            "11:11:39 | Loading existing model params from /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/twitter_ft/model\n",
            "11:11:40 | Opt:\n",
            "11:11:40 |     activation: gelu\n",
            "11:11:40 |     adafactor_eps: '(1e-30, 0.001)'\n",
            "11:11:40 |     adam_eps: 1e-08\n",
            "11:11:40 |     add_p1_after_newln: False\n",
            "11:11:40 |     aggregate_micro: False\n",
            "11:11:40 |     allow_missing_init_opts: False\n",
            "11:11:40 |     attention_dropout: 0.0\n",
            "11:11:40 |     batch_length_range: 5\n",
            "11:11:40 |     batch_sort_cache_type: pop\n",
            "11:11:40 |     batch_sort_field: text\n",
            "11:11:40 |     batchsize: 16\n",
            "11:11:40 |     beam_block_full_context: False\n",
            "11:11:40 |     beam_block_list_filename: None\n",
            "11:11:40 |     beam_block_ngram: -1\n",
            "11:11:40 |     beam_context_block_ngram: -1\n",
            "11:11:40 |     beam_delay: 30\n",
            "11:11:40 |     beam_length_penalty: 0.65\n",
            "11:11:41 |     beam_min_length: 1\n",
            "11:11:41 |     beam_size: 1\n",
            "11:11:41 |     betas: '[0.9, 0.999]'\n",
            "11:11:41 |     bpe_add_prefix_space: None\n",
            "11:11:41 |     bpe_debug: False\n",
            "11:11:41 |     bpe_dropout: None\n",
            "11:11:41 |     bpe_merge: None\n",
            "11:11:41 |     bpe_vocab: None\n",
            "11:11:41 |     checkpoint_activations: False\n",
            "11:11:41 |     compute_tokenized_bleu: False\n",
            "11:11:41 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "11:11:41 |     datatype: train\n",
            "11:11:41 |     delimiter: '\\n'\n",
            "11:11:41 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "11:11:41 |     dict_endtoken: __end__\n",
            "11:11:41 |     dict_file: /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/twitter_ft/model.dict\n",
            "11:11:41 |     dict_include_test: False\n",
            "11:11:41 |     dict_include_valid: False\n",
            "11:11:41 |     dict_initpath: None\n",
            "11:11:41 |     dict_language: english\n",
            "11:11:41 |     dict_loaded: True\n",
            "11:11:41 |     dict_lower: True\n",
            "11:11:41 |     dict_max_ngram_size: -1\n",
            "11:11:41 |     dict_maxexs: -1\n",
            "11:11:41 |     dict_maxtokens: -1\n",
            "11:11:41 |     dict_minfreq: 0\n",
            "11:11:41 |     dict_nulltoken: __null__\n",
            "11:11:41 |     dict_starttoken: __start__\n",
            "11:11:41 |     dict_textfields: text,labels\n",
            "11:11:41 |     dict_tokenizer: bpe\n",
            "11:11:41 |     dict_unktoken: __unk__\n",
            "11:11:41 |     display_add_fields: \n",
            "11:11:41 |     display_examples: False\n",
            "11:11:41 |     display_prettify: False\n",
            "11:11:41 |     download_path: None\n",
            "11:11:41 |     dropout: 0.1\n",
            "11:11:41 |     dynamic_batching: None\n",
            "11:11:41 |     embedding_projection: random\n",
            "11:11:41 |     embedding_size: 512\n",
            "11:11:41 |     embedding_type: random\n",
            "11:11:41 |     embeddings_scale: True\n",
            "11:11:41 |     eval_batchsize: None\n",
            "11:11:41 |     evaltask: None\n",
            "11:11:41 |     ffn_size: 2048\n",
            "11:11:41 |     force_fp16_tokens: False\n",
            "11:11:41 |     fp16: False\n",
            "11:11:41 |     fp16_impl: safe\n",
            "11:11:41 |     gpu: -1\n",
            "11:11:41 |     gradient_clip: 0.1\n",
            "11:11:41 |     hide_labels: False\n",
            "11:11:41 |     history_add_global_end_token: None\n",
            "11:11:41 |     history_reversed: False\n",
            "11:11:41 |     history_size: -1\n",
            "11:11:41 |     image_cropsize: 224\n",
            "11:11:41 |     image_encoder_num_layers: 1\n",
            "11:11:41 |     image_features_dim: 2048\n",
            "11:11:41 |     image_fusion_type: late\n",
            "11:11:41 |     image_mode: no_image_model\n",
            "11:11:41 |     image_size: 256\n",
            "11:11:41 |     include_image_token: True\n",
            "11:11:41 |     inference: greedy\n",
            "11:11:41 |     init_model: data/models/dodecadialogue/base_model/model\n",
            "11:11:41 |     init_opt: None\n",
            "11:11:41 |     interactive_mode: True\n",
            "11:11:41 |     interactive_task: True\n",
            "11:11:41 |     invsqrt_lr_decay_gamma: -1\n",
            "11:11:41 |     is_debug: False\n",
            "11:11:41 |     label_truncate: 128\n",
            "11:11:41 |     learn_positional_embeddings: True\n",
            "11:11:41 |     learningrate: 2.5e-06\n",
            "11:11:41 |     local_human_candidates_file: None\n",
            "11:11:41 |     log_every_n_secs: 10.0\n",
            "11:11:41 |     log_keep_fields: all\n",
            "11:11:41 |     loglevel: info\n",
            "11:11:41 |     lr_scheduler: reduceonplateau\n",
            "11:11:41 |     lr_scheduler_decay: 0.5\n",
            "11:11:41 |     lr_scheduler_patience: 3\n",
            "11:11:41 |     max_train_time: 84600.0\n",
            "11:11:41 |     metrics: default\n",
            "11:11:41 |     model: image_seq2seq\n",
            "11:11:41 |     model_file: /usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/twitter_ft/model\n",
            "11:11:41 |     model_parallel: False\n",
            "11:11:41 |     momentum: 0\n",
            "11:11:41 |     multitask_weights: [1]\n",
            "11:11:41 |     n_decoder_layers: -1\n",
            "11:11:41 |     n_encoder_layers: -1\n",
            "11:11:41 |     n_heads: 16\n",
            "11:11:41 |     n_image_channels: 1\n",
            "11:11:41 |     n_image_tokens: 1\n",
            "11:11:41 |     n_layers: 8\n",
            "11:11:41 |     n_positions: 512\n",
            "11:11:41 |     n_segments: 0\n",
            "11:11:41 |     nesterov: True\n",
            "11:11:41 |     no_cuda: False\n",
            "11:11:41 |     num_epochs: -1\n",
            "11:11:41 |     numthreads: 1\n",
            "11:11:41 |     numworkers: 4\n",
            "11:11:41 |     nus: [0.7]\n",
            "11:11:41 |     optimizer: adamax\n",
            "11:11:41 |     outfile: \n",
            "11:11:41 |     output_scaling: 1.0\n",
            "11:11:41 |     override: \"{'model_file': '/usr/local/lib/python3.7/dist-packages/data/models/dodecadialogue/twitter_ft/model'}\"\n",
            "11:11:41 |     parlai_home: /checkpoint/kshuster/projects/parlall/parlall_MT_plus_FT/parlall_MT_plus_FT_sweep1_Tue_Oct_29/ParlAI\n",
            "11:11:41 |     person_tokens: False\n",
            "11:11:41 |     pytorch_context_length: -1\n",
            "11:11:41 |     pytorch_datapath: None\n",
            "11:11:41 |     pytorch_include_labels: True\n",
            "11:11:41 |     pytorch_preprocess: False\n",
            "11:11:41 |     pytorch_teacher_batch_sort: False\n",
            "11:11:41 |     pytorch_teacher_dataset: None\n",
            "11:11:41 |     pytorch_teacher_task: None\n",
            "11:11:41 |     rank_candidates: False\n",
            "11:11:41 |     relu_dropout: 0.0\n",
            "11:11:41 |     save_after_valid: True\n",
            "11:11:41 |     save_every_n_secs: -1\n",
            "11:11:41 |     save_format: conversations\n",
            "11:11:41 |     share_word_embeddings: True\n",
            "11:11:41 |     short_final_eval: False\n",
            "11:11:41 |     show_advanced_args: False\n",
            "11:11:41 |     shuffle: False\n",
            "11:11:41 |     single_turn: False\n",
            "11:11:41 |     skip_generation: True\n",
            "11:11:41 |     special_tok_lst: None\n",
            "11:11:41 |     split_lines: False\n",
            "11:11:41 |     starttime: Oct29_07-56\n",
            "11:11:41 |     task: twitter\n",
            "11:11:41 |     temperature: 1.0\n",
            "11:11:41 |     tensorboard_log: False\n",
            "11:11:41 |     text_truncate: 512\n",
            "11:11:41 |     topk: 10\n",
            "11:11:41 |     topp: 0.9\n",
            "11:11:41 |     truncate: -1\n",
            "11:11:41 |     update_freq: 1\n",
            "11:11:41 |     use_reply: label\n",
            "11:11:41 |     validation_cutoff: 1.0\n",
            "11:11:41 |     validation_every_n_epochs: -1\n",
            "11:11:41 |     validation_every_n_secs: 3600.0\n",
            "11:11:41 |     validation_max_exs: -1\n",
            "11:11:41 |     validation_metric: ppl\n",
            "11:11:41 |     validation_metric_mode: min\n",
            "11:11:41 |     validation_patience: 10\n",
            "11:11:41 |     validation_share_agent: False\n",
            "11:11:41 |     variant: xlm\n",
            "11:11:41 |     verbose: False\n",
            "11:11:41 |     warmup_rate: 0.0001\n",
            "11:11:41 |     warmup_updates: 2000\n",
            "11:11:41 |     weight_decay: None\n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "11:11:41 | creating task(s): interactive\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m how are you\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m good how are you\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m have you taken your medcine\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m good how are you\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m do you need to use the toilet\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m good how are you doing\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m what is your favourite colour\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m good how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m when is your birthday\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m good how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m are you hungry\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m doing good how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are you doing how are\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [exit]\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m doing so much better than i was before i started this\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m do you feel comfortable with the tempreture\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m doing so much better than i was before i started this\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m can you answer?\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m doing so much better than i was before i started this\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m ?\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m doing so much better than i was before i started this . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m are you bot?\n",
            "\u001b[0;34m[ImageSeq2seq]:\u001b[0;0m \u001b[1mi ' m so happy for you\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [EXIT]\n",
            "CHAT DONE \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oO3MaXpCsAp",
        "outputId": "6abd4910-7e3c-47de-bff2-cc21bbd76762"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.4.24)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# call it with particular args\n",
        "Interactive.main(\n",
        "    # the model_file is a filename path pointing to a particular model dump.\n",
        "    # Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\n",
        "    # They'll be automatically downloaded when you ask to use them.\n",
        "    model_file='zoo:blenderbot2/blenderbot2_400M/model'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "37a5793d69464cdab1846b4475c10448",
            "4fd47d89e0b142f89ac198f7e0bf1751",
            "1deb4878c5364fbeb76add24e064a833",
            "5131a13f9b44497bbad68a90a9461c33",
            "f22acd93847e425da149cf9529a6ee9b",
            "b0755c64755e4f1d9b54ddd1da9388eb",
            "97f80eb305164be7a943a0c4955c0474",
            "e936afde792147c2b7d0616aa4298302",
            "194d57cbb03d44f0b5df7c8b1e5b2e44",
            "f3219d15b29449b1a648d3b0631bea9a",
            "e09940e9b79c47e5b50529d0f4a77ca1",
            "dbe7e284e31248e3a007a7e3e119f476",
            "ee591e8629db467facb28e24d52c2eb5",
            "f83270d5917749f4938d6e5881b489b3",
            "6e4ff6917ee44d7499bf8b29c65a6ad4",
            "746b76d5448043268f34a7cbd5f9cfd3",
            "dcf269ce78d543b09392ce3cd35f4075",
            "a969c0d315d449d28fdb3cfe317042bc",
            "fc286642d55b41558b1e06999eded6a2",
            "d85c5e1955a6430fb2ab93d14e1d5b4a",
            "d2a843f3180b473cbe1cfc680a4784c5",
            "c52ab3307ae54278aa5f6b79f2cadc4a",
            "ab838144cce74a32aa16fefde50a6ebd",
            "1f3073f2b7fe4e2daf6529718a60d27e",
            "b941c4a814d0447a86440de261173faf",
            "21c6907ab6344fb5b28fdaeb96cb2550",
            "c96ac7c78f244c65b96e46f1b09c7909",
            "1fa202de7d5e4ddfad81e990a39972f1",
            "da54d60c7b9d471191bb516b06127ac6",
            "682e619361964ac0a222a8586f4695ff",
            "00b04c4e9a8648d6bbe43352ae7257b7",
            "63dd0ee2f28b45cb979b5ce50341a458",
            "28c157103b5e4aa7a4b09bf5911d63da",
            "c86246e548bf4d91af9d2bba7506db4c",
            "bcee82fd36984aceabcf2bf0ec6cdab2",
            "ebd24735e0e74f5baf950454f63b795a",
            "a6a7f8dc0d4840669ec821fad4e036a2",
            "4d7c899d5b1740d7a8824aa90a8cd256",
            "77ecea37aa45456590930325a4a3ee10",
            "c93ad2b31a284bf1aef6fc1acf45ad44",
            "ba61cd825ff34427ac6578a218ee8083",
            "22c346e6acb94394a49794858e14e33e",
            "7ba25ba1d0d9467c8e855ad379bd538e",
            "15f9feaddd9d4d8f92030c70db1cbc5b"
          ]
        },
        "id": "AxP1AOnUAbGo",
        "outputId": "782f5015-9fb6-48cc-db63-33735ccd2ebf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:18:46 | \u001b[33mOverriding opt[\"model_file\"] to /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/blenderbot2_400M/model (previously: /checkpoint/kshuster/projects/knowledge_bot/kbot_memfix_sweep25_Fri_Jul__9/338/model.oss)\u001b[0m\n",
            "11:18:46 | loading dictionary from /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/blenderbot2_400M/model.dict\n",
            "11:18:46 | num words = 50264\n",
            "11:18:46 | Downloading https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe to /usr/local/lib/python3.7/dist-packages/data/gpt2/vocab.bpe\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading vocab.bpe: 0.00B [00:00, ?B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:18:47 | Downloading https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json to /usr/local/lib/python3.7/dist-packages/data/gpt2/encoder.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Downloading encoder.json: 0.00B [00:00, ?B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:18:47 | BlenderBot2Fid: full interactive mode on.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37a5793d69464cdab1846b4475c10448"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbe7e284e31248e3a007a7e3e119f476"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab838144cce74a32aa16fefde50a6ebd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c86246e548bf4d91af9d2bba7506db4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:19:02 | building data: /usr/local/lib/python3.7/dist-packages/data/models/hallucination/bart_rag_token/model.tgz\n",
            "11:19:02 | Downloading http://parl.ai/downloads/_models/hallucination/bart_rag_token/model.tgz to /usr/local/lib/python3.7/dist-packages/data/models/hallucination/bart_rag_token/model.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading model.tgz: 100%|██████████| 950M/950M [00:18<00:00, 51.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11:19:44 | Creating the search engine retriever.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f1a6fa6e0d1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# They'll be automatically downloaded when you ask to use them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zoo:blenderbot2/blenderbot2_400M/model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_kwargs\u001b[0;34m(cls, kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_from_parser_and_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_from_parser_and_opt\u001b[0;34m(cls, opt, parser)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/scripts/interactive.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/scripts/interactive.py\u001b[0m in \u001b[0;36minteractive\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Create model and assign it to the specified task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequireModelExists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mhuman_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalHumanAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/agents.py\u001b[0m in \u001b[0;36mcreate_agent\u001b[0;34m(opt, requireModelExists)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;31m# Attempt to load the model from the model file first (this way we do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;31m# not even have to specify the model name as a parameter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_agent_from_opt_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/agents.py\u001b[0m in \u001b[0;36mcreate_agent_from_opt_file\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;31m# loaded ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0mcompare_init_model_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_from_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_from_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/agents/rag/rag.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt, shared)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Super call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generation_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrag_model_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rag_model_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/agents/bart/bart.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt, shared)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_bart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize_bart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOpt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOpt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/torch_generator_agent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt, shared)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mfsdp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_fsdp_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsdp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdp_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfsdp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelay_halving\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/projects/blenderbot2/agents/blenderbot2.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5BlenderBot2FidModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlenderBot2FidModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embedding_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'random'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m             self._copy_embeddings(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/projects/blenderbot2/agents/modules.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt, dictionary, retriever_shared)\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDictionaryAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretriever_shared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         super().__init__(\n\u001b[0;32m--> 836\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretriever_shared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretriever_shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m         )  # type: ignore\n\u001b[1;32m    838\u001b[0m         self._rag_model_interface = BlenderBot2Fid(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/projects/blenderbot2/agents/modules.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt, dictionary, retriever_shared)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy_retriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummyRetriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretriever_shared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretriever\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         query_encoder = (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/projects/blenderbot2/agents/modules.py\u001b[0m in \u001b[0;36mretriever_factory\u001b[0;34m(opt, dictionary, shared)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mretriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetrieverType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rag_retriever_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretriever\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mRetrieverType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSEARCH_ENGINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBB2SearchQuerySearchEngineRetriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mretriever\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mRetrieverType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSEARCH_TERM_FAISS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBB2SearchQueryFaissIndexRetriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/agents/rag/retrievers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt, dictionary, shared)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitiate_retriever_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'search_client'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/agents/rag/retrievers.py\u001b[0m in \u001b[0;36minitiate_retriever_api\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitiate_retriever_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSearchEngineRetriever\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Creating the search engine retriever.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSearchEngineRetriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_empty_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/agents/rag/retrieve_api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_address\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'search_server'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_query_search_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/agents/rag/retrieve_api.py\u001b[0m in \u001b[0;36m_validate_server\u001b[0;34m(self, address)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Must provide a valid server for search'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Must provide a valid server for search"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install msc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bbuSCuswGAsP",
        "outputId": "47e48dde-2554-40d3-8e21-5fa617f09c61"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting msc\n",
            "  Downloading msc-1.1.20-py3-none-any.whl (8.8 kB)\n",
            "Collecting redis==2.10.6\n",
            "  Downloading redis-2.10.6-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting Flask==1.0.2\n",
            "  Downloading Flask-1.0.2-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting mongoengine==0.15.3\n",
            "  Downloading mongoengine-0.15.3.tar.gz (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 51.7 MB/s \n",
            "\u001b[?25hCollecting uuid==1.30\n",
            "  Downloading uuid-1.30.tar.gz (5.8 kB)\n",
            "Collecting requests==2.20.0\n",
            "  Downloading requests-2.20.0-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting kafka==1.3.5\n",
            "  Downloading kafka-1.3.5-py2.py3-none-any.whl (207 kB)\n",
            "\u001b[K     |████████████████████████████████| 207 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting colorama==0.4.0\n",
            "  Downloading colorama-0.4.0-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: geopy==1.17.0 in /usr/local/lib/python3.7/dist-packages (from msc) (1.17.0)\n",
            "Collecting jsonmerge==1.5.1\n",
            "  Downloading jsonmerge-1.5.1.tar.gz (20 kB)\n",
            "Collecting simplejson==3.16.0\n",
            "  Downloading simplejson-3.16.0.tar.gz (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.5 MB/s \n",
            "\u001b[?25hCollecting pymongo==3.7.2\n",
            "  Downloading pymongo-3.7.2-cp37-cp37m-manylinux1_x86_64.whl (406 kB)\n",
            "\u001b[K     |████████████████████████████████| 406 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from Flask==1.0.2->msc) (2.11.3)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask==1.0.2->msc) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask==1.0.2->msc) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.7/dist-packages (from Flask==1.0.2->msc) (1.0.1)\n",
            "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy==1.17.0->msc) (1.52)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from jsonmerge==1.5.1->msc) (4.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mongoengine==0.15.3->msc) (1.15.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.20.0->msc) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.20.0->msc) (2021.10.8)\n",
            "Collecting idna<2.8,>=2.5\n",
            "  Downloading idna-2.7-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.25,>=1.21.1\n",
            "  Downloading urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 56.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10->Flask==1.0.2->msc) (2.0.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->jsonmerge==1.5.1->msc) (20.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->jsonmerge==1.5.1->msc) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->jsonmerge==1.5.1->msc) (5.2.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->jsonmerge==1.5.1->msc) (4.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema->jsonmerge==1.5.1->msc) (4.2.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->jsonmerge==1.5.1->msc) (3.8.0)\n",
            "Building wheels for collected packages: jsonmerge, mongoengine, simplejson, uuid\n",
            "  Building wheel for jsonmerge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonmerge: filename=jsonmerge-1.5.1-py3-none-any.whl size=15577 sha256=0741e3607ae16cb761f57fe004e1cd3aaec868544fc48d6efd13e4f25043e34e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/14/55/8bbf7c994f5fe80bb7af2da6e133715d8b91b532f78cb4fa2e\n",
            "  Building wheel for mongoengine (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mongoengine: filename=mongoengine-0.15.3-py3-none-any.whl size=101420 sha256=827e4d8fe0c85fc643986e4f83a4f0eac8060e12e3b8e4fb9fd390b067076fd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/e1/b7/c9d4f1864a01b914de13177707dce3fdf677553cef02f620da\n",
            "  Building wheel for simplejson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for simplejson: filename=simplejson-3.16.0-cp37-cp37m-linux_x86_64.whl size=114902 sha256=880d3bd0de95a57d27415ea7a0d575ab07f1731a26768c07a750c8b31db3ee37\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/6f/29/109ee3b85a9f9861d4294b05e4597363d5ad3c9dfaccc78787\n",
            "  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uuid: filename=uuid-1.30-py3-none-any.whl size=6503 sha256=28c328222e6e2acd45fa4d479beac317e7f24494aba0588c34960ce09a851daf\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/ea/87/dd57f1ecb4f0752f3e1dbf958ebf8b36d920d190425bcdc24d\n",
            "Successfully built jsonmerge mongoengine simplejson uuid\n",
            "Installing collected packages: urllib3, pymongo, idna, uuid, simplejson, requests, redis, mongoengine, kafka, jsonmerge, Flask, colorama, msc\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.9\n",
            "    Uninstalling urllib3-1.26.9:\n",
            "      Successfully uninstalled urllib3-1.26.9\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.1.1\n",
            "    Uninstalling pymongo-4.1.1:\n",
            "      Successfully uninstalled pymongo-4.1.1\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: Flask\n",
            "    Found existing installation: Flask 1.1.4\n",
            "    Uninstalling Flask-1.1.4:\n",
            "      Successfully uninstalled Flask-1.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.8.0 requires requests<3,>=2.21.0, but you have requests 2.20.0 which is incompatible.\n",
            "responses 0.18.0 requires urllib3>=1.25.10, but you have urllib3 1.24.3 which is incompatible.\n",
            "parlai 1.6.0 requires requests<3,>=2.21.0, but you have requests 2.20.0 which is incompatible.\n",
            "parlai 1.6.0 requires urllib3>=1.26.5, but you have urllib3 1.24.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.20.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "botocore 1.26.3 requires urllib3<1.27,>=1.25.4, but you have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Flask-1.0.2 colorama-0.4.0 idna-2.7 jsonmerge-1.5.1 kafka-1.3.5 mongoengine-0.15.3 msc-1.1.20 pymongo-3.7.2 redis-2.10.6 requests-2.20.0 simplejson-3.16.0 urllib3-1.24.3 uuid-1.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "requests",
                  "urllib3",
                  "uuid"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# call it with particular args\n",
        "Interactive.main(\n",
        "    # the model_file is a filename path pointing to a particular model dump.\n",
        "    # Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\n",
        "    # They'll be automatically downloaded when you ask to use them.\n",
        "    model_file='zoo:msc/msc3B_1024/model'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iM0YAbbaAbK9",
        "outputId": "24f029a8-3af4-41c8-b8fa-70eeac210815"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ba7a0515c975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# They'll be automatically downloaded when you ask to use them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zoo:msc/msc3B_1024/model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_kwargs\u001b[0;34m(cls, kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \"\"\"\n\u001b[1;32m     90\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_from_parser_and_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/params.py\u001b[0m in \u001b[0;36mparse_kwargs\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_captured_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m             \u001b[0mstring_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs_to_str_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstring_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/params.py\u001b[0m in \u001b[0;36m_kwargs_to_str_args\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1230\u001b[0m             \u001b[0;31m# become aware of any extra args that might be specified if the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0;31m# provides something like model=\"transformer/generator\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_extra_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m             \u001b[0;31m# do it again, this time knowing about ALL args.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/params.py\u001b[0m in \u001b[0;36madd_extra_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_model_subargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;31m# add world args, if we know a priori which world is being used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/params.py\u001b[0m in \u001b[0;36madd_model_subargs\u001b[0;34m(self, model, partial)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mAdd\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mspecific\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mparticular\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m         \"\"\"\n\u001b[0;32m--> 822\u001b[0;31m         \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_agent_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'add_cmdline_args'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/parlai/core/loader.py\u001b[0m in \u001b[0;36mload_agent_module\u001b[0;34m(agent_path)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s.agents.%s.%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrepo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mmy_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'projects.msc'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "b145b32f810eb43c2063de074adc33bebdb31f281146d1ebd2b29b2a536b3312"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('parlai')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Ash of parlai-model-test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37a5793d69464cdab1846b4475c10448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fd47d89e0b142f89ac198f7e0bf1751",
              "IPY_MODEL_1deb4878c5364fbeb76add24e064a833",
              "IPY_MODEL_5131a13f9b44497bbad68a90a9461c33"
            ],
            "layout": "IPY_MODEL_f22acd93847e425da149cf9529a6ee9b"
          }
        },
        "4fd47d89e0b142f89ac198f7e0bf1751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0755c64755e4f1d9b54ddd1da9388eb",
            "placeholder": "​",
            "style": "IPY_MODEL_97f80eb305164be7a943a0c4955c0474",
            "value": "Downloading: 100%"
          }
        },
        "1deb4878c5364fbeb76add24e064a833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e936afde792147c2b7d0616aa4298302",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_194d57cbb03d44f0b5df7c8b1e5b2e44",
            "value": 28
          }
        },
        "5131a13f9b44497bbad68a90a9461c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3219d15b29449b1a648d3b0631bea9a",
            "placeholder": "​",
            "style": "IPY_MODEL_e09940e9b79c47e5b50529d0f4a77ca1",
            "value": " 28.0/28.0 [00:00&lt;00:00, 478B/s]"
          }
        },
        "f22acd93847e425da149cf9529a6ee9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0755c64755e4f1d9b54ddd1da9388eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97f80eb305164be7a943a0c4955c0474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e936afde792147c2b7d0616aa4298302": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "194d57cbb03d44f0b5df7c8b1e5b2e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3219d15b29449b1a648d3b0631bea9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09940e9b79c47e5b50529d0f4a77ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbe7e284e31248e3a007a7e3e119f476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee591e8629db467facb28e24d52c2eb5",
              "IPY_MODEL_f83270d5917749f4938d6e5881b489b3",
              "IPY_MODEL_6e4ff6917ee44d7499bf8b29c65a6ad4"
            ],
            "layout": "IPY_MODEL_746b76d5448043268f34a7cbd5f9cfd3"
          }
        },
        "ee591e8629db467facb28e24d52c2eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcf269ce78d543b09392ce3cd35f4075",
            "placeholder": "​",
            "style": "IPY_MODEL_a969c0d315d449d28fdb3cfe317042bc",
            "value": "Downloading: 100%"
          }
        },
        "f83270d5917749f4938d6e5881b489b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc286642d55b41558b1e06999eded6a2",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d85c5e1955a6430fb2ab93d14e1d5b4a",
            "value": 231508
          }
        },
        "6e4ff6917ee44d7499bf8b29c65a6ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2a843f3180b473cbe1cfc680a4784c5",
            "placeholder": "​",
            "style": "IPY_MODEL_c52ab3307ae54278aa5f6b79f2cadc4a",
            "value": " 226k/226k [00:00&lt;00:00, 904kB/s]"
          }
        },
        "746b76d5448043268f34a7cbd5f9cfd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcf269ce78d543b09392ce3cd35f4075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a969c0d315d449d28fdb3cfe317042bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc286642d55b41558b1e06999eded6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d85c5e1955a6430fb2ab93d14e1d5b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2a843f3180b473cbe1cfc680a4784c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c52ab3307ae54278aa5f6b79f2cadc4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab838144cce74a32aa16fefde50a6ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f3073f2b7fe4e2daf6529718a60d27e",
              "IPY_MODEL_b941c4a814d0447a86440de261173faf",
              "IPY_MODEL_21c6907ab6344fb5b28fdaeb96cb2550"
            ],
            "layout": "IPY_MODEL_c96ac7c78f244c65b96e46f1b09c7909"
          }
        },
        "1f3073f2b7fe4e2daf6529718a60d27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fa202de7d5e4ddfad81e990a39972f1",
            "placeholder": "​",
            "style": "IPY_MODEL_da54d60c7b9d471191bb516b06127ac6",
            "value": "Downloading: 100%"
          }
        },
        "b941c4a814d0447a86440de261173faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_682e619361964ac0a222a8586f4695ff",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00b04c4e9a8648d6bbe43352ae7257b7",
            "value": 466062
          }
        },
        "21c6907ab6344fb5b28fdaeb96cb2550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63dd0ee2f28b45cb979b5ce50341a458",
            "placeholder": "​",
            "style": "IPY_MODEL_28c157103b5e4aa7a4b09bf5911d63da",
            "value": " 455k/455k [00:00&lt;00:00, 819kB/s]"
          }
        },
        "c96ac7c78f244c65b96e46f1b09c7909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa202de7d5e4ddfad81e990a39972f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da54d60c7b9d471191bb516b06127ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "682e619361964ac0a222a8586f4695ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00b04c4e9a8648d6bbe43352ae7257b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63dd0ee2f28b45cb979b5ce50341a458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28c157103b5e4aa7a4b09bf5911d63da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c86246e548bf4d91af9d2bba7506db4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcee82fd36984aceabcf2bf0ec6cdab2",
              "IPY_MODEL_ebd24735e0e74f5baf950454f63b795a",
              "IPY_MODEL_a6a7f8dc0d4840669ec821fad4e036a2"
            ],
            "layout": "IPY_MODEL_4d7c899d5b1740d7a8824aa90a8cd256"
          }
        },
        "bcee82fd36984aceabcf2bf0ec6cdab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77ecea37aa45456590930325a4a3ee10",
            "placeholder": "​",
            "style": "IPY_MODEL_c93ad2b31a284bf1aef6fc1acf45ad44",
            "value": "Downloading: 100%"
          }
        },
        "ebd24735e0e74f5baf950454f63b795a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba61cd825ff34427ac6578a218ee8083",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22c346e6acb94394a49794858e14e33e",
            "value": 570
          }
        },
        "a6a7f8dc0d4840669ec821fad4e036a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ba25ba1d0d9467c8e855ad379bd538e",
            "placeholder": "​",
            "style": "IPY_MODEL_15f9feaddd9d4d8f92030c70db1cbc5b",
            "value": " 570/570 [00:00&lt;00:00, 13.2kB/s]"
          }
        },
        "4d7c899d5b1740d7a8824aa90a8cd256": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ecea37aa45456590930325a4a3ee10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93ad2b31a284bf1aef6fc1acf45ad44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba61cd825ff34427ac6578a218ee8083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22c346e6acb94394a49794858e14e33e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ba25ba1d0d9467c8e855ad379bd538e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15f9feaddd9d4d8f92030c70db1cbc5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}